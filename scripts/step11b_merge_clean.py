# step11b_merge_clean.py
# ä½ç½®ï¼š/Users/pluviophile/graph/1025/scripts/step11b_merge_clean.py
# 
# åŠŸèƒ½ï¼šåˆå¹¶step10çš„åŠŸèƒ½æ›´æ–° + Phase 1çš„åŸºå› IDï¼Œæ¸…ç†v4å¼•å…¥çš„ç©ºå­—æ®µ

import pandas as pd

print("=== Step 11b: åˆå¹¶æ¸…ç† - step10æ›´æ–° + Phase 1åŸºå› ID ===\n")

# è·¯å¾„é…ç½®
base_path = '/Users/pluviophile/graph/1025/data/processed'

# è¾“å…¥æ–‡ä»¶
v5_file = f'{base_path}/protein_master_v5_final.tsv'        # step10è¾“å‡º
v3_gene_file = f'{base_path}/protein_master_v3_with_gene_ids.tsv'  # Phase 1è¾“å‡º

# è¾“å‡ºæ–‡ä»¶
output_file = f'{base_path}/protein_master_v6_clean.tsv'

print("=" * 70)
print("ğŸ“‹ æ–‡ä»¶è·¯å¾„")
print("=" * 70)
print(f"v5 (step10è¾“å‡º):      {v5_file}")
print(f"v3+åŸºå› ID (Phase 1):  {v3_gene_file}")
print(f"è¾“å‡º (v6 clean):      {output_file}\n")

# 1. è¯»å–v5ï¼ˆstep10çš„æ›´æ–°ï¼‰
print("1. è¯»å–step10è¾“å‡ºï¼ˆv5ï¼‰...")
try:
    df_v5 = pd.read_csv(v5_file, sep='\t')
    print(f"   âœ… æ€»è›‹ç™½æ•°: {len(df_v5)}")
    print(f"   âœ… åˆ—æ•°: {len(df_v5.columns)}")
except Exception as e:
    print(f"   âŒ è¯»å–å¤±è´¥: {e}")
    exit(1)

# 2. è¯»å–v3_with_gene_idsï¼ˆå¹²å‡€ç‰ˆæœ¬ï¼‰
print("\n2. è¯»å–Phase 1è¾“å‡ºï¼ˆv3+åŸºå› IDï¼‰...")
try:
    df_clean = pd.read_csv(v3_gene_file, sep='\t')
    print(f"   âœ… æ€»è›‹ç™½æ•°: {len(df_clean)}")
    print(f"   âœ… åˆ—æ•°: {len(df_clean.columns)}")
except Exception as e:
    print(f"   âŒ è¯»å–å¤±è´¥: {e}")
    exit(1)

# 3. éªŒè¯æ•°æ®ä¸€è‡´æ€§
print("\n3. éªŒè¯æ•°æ®ä¸€è‡´æ€§...")
if len(df_v5) != len(df_clean):
    print(f"   âš ï¸ è­¦å‘Šï¼šè¡Œæ•°ä¸ä¸€è‡´ (v5: {len(df_v5)}, v3: {len(df_clean)})")
else:
    print(f"   âœ… è¡Œæ•°ä¸€è‡´: {len(df_v5)}")

# æ£€æŸ¥uniprot_idæ˜¯å¦åŒ¹é…
v5_ids = set(df_v5['uniprot_id'])
v3_ids = set(df_clean['uniprot_id'])
common_ids = v5_ids & v3_ids
print(f"   âœ… å…±åŒIDæ•°: {len(common_ids)}/{len(df_clean)}")

# 4. æå–step10æ›´æ–°çš„å­—æ®µ
print("\n4. æå–step10æ›´æ–°çš„4ä¸ªå­—æ®µ...")
function_fields = ['function', 'go_biological_process', 
                   'go_molecular_function', 'go_cellular_component']

# æ£€æŸ¥å­—æ®µæ˜¯å¦å­˜åœ¨
missing_fields = [f for f in function_fields if f not in df_v5.columns]
if missing_fields:
    print(f"   âš ï¸ v5ä¸­ç¼ºå°‘å­—æ®µ: {missing_fields}")
    print("   ä½¿ç”¨v5ä¸­å­˜åœ¨çš„å­—æ®µ...")
    function_fields = [f for f in function_fields if f in df_v5.columns]

print(f"   æå–å­—æ®µ: {function_fields}")
df_updates = df_v5[['uniprot_id'] + function_fields].copy()

# 5. ç»Ÿè®¡æ›´æ–°è¦†ç›–ç‡
print("\n5. step10æ›´æ–°ç»Ÿè®¡:")
for field in function_fields:
    if field in df_updates.columns:
        has_data = df_updates[field].notna() & (df_updates[field] != '')
        print(f"   {field:30} {has_data.sum():,}/{len(df_updates):,} ({has_data.sum()/len(df_updates)*100:.1f}%)")

# 6. æ›´æ–°åˆ°å¹²å‡€ç‰ˆæœ¬
print("\n6. åˆå¹¶æ›´æ–°åˆ°å¹²å‡€ç‰ˆæœ¬...")

# å…ˆåˆ é™¤v3_with_gene_idsä¸­çš„è¿™4ä¸ªå­—æ®µï¼ˆå¦‚æœå­˜åœ¨ï¼‰
for field in function_fields:
    if field in df_clean.columns:
        df_clean = df_clean.drop(columns=[field])
        print(f"   åˆ é™¤æ—§å­—æ®µ: {field}")

# åˆå¹¶æ›´æ–°
print("   æ‰§è¡Œåˆå¹¶...")
df_final = df_clean.merge(df_updates, on='uniprot_id', how='left')

print(f"   âœ… åˆå¹¶å®Œæˆ")

# 7. éªŒè¯æœ€ç»ˆç»“æœ
print("\n7. éªŒè¯æœ€ç»ˆæ•°æ®...")
print(f"   è¡Œæ•°: {len(df_final)} (åº”è¯¥ = {len(df_clean)})")
print(f"   åˆ—æ•°: {len(df_final.columns)}")

if len(df_final) != len(df_clean):
    print(f"   âš ï¸ è­¦å‘Šï¼šåˆå¹¶åè¡Œæ•°å˜åŒ–ï¼")
else:
    print(f"   âœ… è¡Œæ•°ä¿æŒä¸å˜")

# 8. ç»Ÿè®¡æœ€ç»ˆå­—æ®µè¦†ç›–ç‡
print("\n8. æœ€ç»ˆå­—æ®µè¦†ç›–ç‡:")

# åŸºå› IDå­—æ®µ
gene_id_fields = ['ncbi_gene_id', 'ensembl_gene_id', 'gene_synonyms']
print("\n   åŸºå› IDå­—æ®µ (Phase 1):")
for field in gene_id_fields:
    if field in df_final.columns:
        has_data = df_final[field].notna() & (df_final[field] != '')
        print(f"      {field:25} {has_data.sum():,}/{len(df_final):,} ({has_data.sum()/len(df_final)*100:.1f}%)")

# åŠŸèƒ½æ³¨é‡Šå­—æ®µ
print("\n   åŠŸèƒ½æ³¨é‡Šå­—æ®µ (step10æ›´æ–°):")
for field in function_fields:
    if field in df_final.columns:
        has_data = df_final[field].notna() & (df_final[field] != '')
        print(f"      {field:30} {has_data.sum():,}/{len(df_final):,} ({has_data.sum()/len(df_final)*100:.1f}%)")

# 9. åˆ—å‡ºæ‰€æœ‰å­—æ®µ
print(f"\n9. v6_cleanå­—æ®µåˆ—è¡¨ ({len(df_final.columns)}åˆ—):")
for i, col in enumerate(df_final.columns, 1):
    print(f"   {i:2}. {col}")

# 10. ä¿å­˜
print(f"\n10. ä¿å­˜å¹²å‡€çš„v6...")
try:
    df_final.to_csv(output_file, sep='\t', index=False)
    print(f"    âœ… ä¿å­˜æˆåŠŸ")
except Exception as e:
    print(f"    âŒ ä¿å­˜å¤±è´¥: {e}")
    exit(1)

# 11. æœ€ç»ˆæ€»ç»“
print(f"\n{'='*70}")
print("âœ… åˆå¹¶æ¸…ç†å®Œæˆï¼")
print(f"{'='*70}")
print(f"è¾“å‡ºæ–‡ä»¶: {output_file}")
print(f"è¡Œæ•°: {len(df_final):,}")
print(f"åˆ—æ•°: {len(df_final.columns)}")
print(f"\næ•°æ®æ¥æº:")
print(f"  âœ… v3åŸå§‹29åˆ— (åŸºç¡€ä¿¡æ¯)")
print(f"  âœ… Phase 1çš„4åˆ— (åŸºå› IDæ˜ å°„)")
print(f"  âœ… step10çš„4åˆ— (åŠŸèƒ½+GOæ³¨é‡Šæ›´æ–°)")
print(f"\né¢„æœŸåˆ—æ•°: 33åˆ— (29 + 4åŸºå› ID)")
print(f"å®é™…åˆ—æ•°: {len(df_final.columns)}åˆ—")

if len(df_final.columns) == 33:
    print("\nğŸ‰ åˆ—æ•°æ­£ç¡®ï¼æ•°æ®ç»“æ„å®Œæ•´ï¼")
elif len(df_final.columns) > 33:
    print(f"\nâš ï¸ åˆ—æ•°å¤šäºé¢„æœŸï¼Œå¯èƒ½æœ‰å†—ä½™å­—æ®µ")
    extra_cols = len(df_final.columns) - 33
    print(f"   å¤šå‡º{extra_cols}åˆ—ï¼Œè¯·æ£€æŸ¥")
else:
    print(f"\nâš ï¸ åˆ—æ•°å°‘äºé¢„æœŸï¼Œå¯èƒ½æœ‰å­—æ®µç¼ºå¤±")

# 12. ç¤ºä¾‹æ•°æ®
print(f"\nç¤ºä¾‹æ•°æ®ï¼ˆå‰2è¡Œï¼‰:")
print("="*70)
example_cols = ['uniprot_id', 'gene_names', 'ncbi_gene_id', 'ensembl_gene_id', 
                'function', 'go_biological_process']
available_cols = [c for c in example_cols if c in df_final.columns]
print(df_final[available_cols].head(2).to_string())

print(f"\n{'='*70}")
print("ä¸‹ä¸€æ­¥: python step12_add_uniprot_metadata.py")
print(f"{'='*70}\n")
